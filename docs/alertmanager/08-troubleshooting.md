# ğŸ”§ MÃ³dulo 8: Troubleshooting do Alertmanager

> **Objetivo:** Aprender a diagnosticar e resolver problemas comuns do Alertmanager

---

## ğŸ“‹ ÃNDICE

1. [DiagnÃ³stico Inicial](#1-diagnÃ³stico-inicial)
2. [Logs e Debugging](#2-logs-e-debugging)
3. [MÃ©tricas de Monitoramento](#3-mÃ©tricas-de-monitoramento)
4. [Problemas de ConfiguraÃ§Ã£o](#4-problemas-de-configuraÃ§Ã£o)
5. [Problemas de Conectividade](#5-problemas-de-conectividade)
6. [Problemas de NotificaÃ§Ã£o](#6-problemas-de-notificaÃ§Ã£o)
7. [Problemas de Performance](#7-problemas-de-performance)
8. [Ferramentas de DiagnÃ³stico](#8-ferramentas-de-diagnÃ³stico)
9. [CenÃ¡rios Comuns](#9-cenÃ¡rios-comuns)
10. [PrevenÃ§Ã£o de Problemas](#10-prevenÃ§Ã£o-de-problemas)

---

## 1. DIAGNÃ“STICO INICIAL

### ğŸ©º Checklist de SaÃºde

#### âœ… VerificaÃ§Ãµes BÃ¡sicas
```bash
# 1. Status do serviÃ§o
docker-compose ps alertmanager

# 2. Logs recentes
docker-compose logs --tail=50 alertmanager

# 3. Conectividade
curl -s http://localhost:9093/-/healthy

# 4. ConfiguraÃ§Ã£o vÃ¡lida
docker exec alertmanager amtool config show

# 5. Alertas ativos
curl -s http://localhost:9093/api/v1/alerts | jq '.data | length'
```

#### ğŸ” Status da Interface Web
```bash
# Verificar se a interface estÃ¡ acessÃ­vel
curl -I http://localhost:9093/

# Verificar API
curl -s http://localhost:9093/api/v1/status | jq '.status'

# Verificar receivers
curl -s http://localhost:9093/api/v1/receivers | jq '.data[].name'
```

### ğŸ“Š Dashboard de SaÃºde

#### ğŸ¯ MÃ©tricas Essenciais
```promql
# Alertmanager estÃ¡ rodando?
up{job="alertmanager"}

# Alertas sendo processados?
rate(alertmanager_alerts_received_total[5m])

# NotificaÃ§Ãµes sendo enviadas?
rate(alertmanager_notifications_total[5m])

# Erros de notificaÃ§Ã£o?
rate(alertmanager_notifications_failed_total[5m])
```

---

## 2. LOGS E DEBUGGING

### ğŸ“ ConfiguraÃ§Ã£o de Logs

#### ğŸ”§ NÃ­veis de Log
```yaml
# alertmanager.yml
global:
  # ConfiguraÃ§Ãµes globais...

# Via linha de comando
command:
  - '--log.level=debug'    # debug, info, warn, error
  - '--log.format=json'    # json ou logfmt
```

#### ğŸ³ Docker Compose com Debug
```yaml
# compose.yml
services:
  alertmanager:
    image: prom/alertmanager:latest
    command:
      - '--config.file=/etc/alertmanager/alertmanager.yml'
      - '--storage.path=/alertmanager'
      - '--web.external-url=http://localhost:9093'
      - '--log.level=debug'
      - '--log.format=json'
    volumes:
      - ./alertmanager.yml:/etc/alertmanager/alertmanager.yml
    ports:
      - "9093:9093"
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"
```

### ğŸ” AnÃ¡lise de Logs

#### ğŸ“‹ Logs Importantes
```bash
# Logs de inicializaÃ§Ã£o
docker-compose logs alertmanager | grep -E "(Starting|Listening|Config)"

# Logs de erro
docker-compose logs alertmanager | grep -E "(ERROR|WARN|error|failed)"

# Logs de notificaÃ§Ã£o
docker-compose logs alertmanager | grep -E "(notification|notify|sent)"

# Logs de configuraÃ§Ã£o
docker-compose logs alertmanager | grep -E "(config|reload|template)"
```

#### ğŸ¯ PadrÃµes de Log
```json
// Log de sucesso na notificaÃ§Ã£o
{
  "level": "info",
  "ts": "2024-01-15T10:30:00.000Z",
  "caller": "notify/notify.go:732",
  "msg": "Completed successfully",
  "receiver": "web.hook",
  "integration": "webhook",
  "attempts": 1
}

// Log de erro na notificaÃ§Ã£o
{
  "level": "error",
  "ts": "2024-01-15T10:30:00.000Z",
  "caller": "notify/webhook.go:108",
  "msg": "Notify attempt failed",
  "receiver": "web.hook",
  "integration": "webhook",
  "attempts": 1,
  "err": "Post \"http://webhook.example.com\": dial tcp: connection refused"
}
```

### ğŸ”§ Debug AvanÃ§ado

#### ğŸ¯ Rastreamento de Alertas
```bash
# Seguir logs em tempo real
docker-compose logs -f alertmanager

# Filtrar por alerta especÃ­fico
docker-compose logs alertmanager | grep "DatabaseDown"

# Filtrar por receiver
docker-compose logs alertmanager | grep "slack-alerts"

# Logs estruturados com jq
docker-compose logs alertmanager --since=1h | \
  grep '^{' | jq 'select(.receiver == "slack-alerts")'
```

---

## 3. MÃ‰TRICAS DE MONITORAMENTO

### ğŸ“Š MÃ©tricas Essenciais

#### ğŸ¯ Alertas Recebidos
```promql
# Taxa de alertas recebidos
rate(alertmanager_alerts_received_total[5m])

# Alertas ativos por estado
alertmanager_alerts{state="active"}
alertmanager_alerts{state="suppressed"}

# Alertas invÃ¡lidos
rate(alertmanager_alerts_invalid_total[5m])
```

#### ğŸ“¤ NotificaÃ§Ãµes
```promql
# Taxa de notificaÃ§Ãµes enviadas
rate(alertmanager_notifications_total[5m])

# Taxa de falhas por receiver
rate(alertmanager_notifications_failed_total[5m]) by (receiver)

# LatÃªncia de notificaÃ§Ãµes
histogram_quantile(0.95, 
  rate(alertmanager_notification_latency_seconds_bucket[5m])
) by (receiver)
```

#### ğŸ”„ ConfiguraÃ§Ã£o
```promql
# Ãšltima recarga de configuraÃ§Ã£o
alertmanager_config_last_reload_success_timestamp_seconds

# Falhas na recarga
rate(alertmanager_config_last_reload_successful[5m]) == 0

# Hash da configuraÃ§Ã£o atual
alertmanager_config_hash
```

### ğŸ“ˆ Dashboard de Monitoramento

#### ğŸ¯ Grafana Dashboard
```json
{
  "dashboard": {
    "title": "Alertmanager Health",
    "panels": [
      {
        "title": "Alerts Received Rate",
        "type": "graph",
        "targets": [{
          "expr": "rate(alertmanager_alerts_received_total[5m])"
        }]
      },
      {
        "title": "Notification Success Rate",
        "type": "stat",
        "targets": [{
          "expr": "(
            rate(alertmanager_notifications_total[5m]) - 
            rate(alertmanager_notifications_failed_total[5m])
          ) / rate(alertmanager_notifications_total[5m]) * 100"
        }]
      },
      {
        "title": "Active Alerts",
        "type": "stat",
        "targets": [{
          "expr": "alertmanager_alerts{state=\"active\"}"
        }]
      }
    ]
  }
}
```

---

## 4. PROBLEMAS DE CONFIGURAÃ‡ÃƒO

### âŒ Erros Comuns

#### ğŸ”§ Sintaxe YAML
```yaml
# âŒ ERRO - IndentaÃ§Ã£o incorreta
route:
default_receiver: 'web.hook'
group_wait: 10s

# âœ… CORRETO - IndentaÃ§Ã£o correta
route:
  default_receiver: 'web.hook'
  group_wait: 10s
```

#### ğŸ“§ ConfiguraÃ§Ã£o de Email
```yaml
# âŒ ERRO - ConfiguraÃ§Ã£o incompleta
receivers:
- name: 'email-alerts'
  email_configs:
  - to: 'admin@example.com'

# âœ… CORRETO - ConfiguraÃ§Ã£o completa
global:
  smtp_smarthost: 'smtp.gmail.com:587'
  smtp_from: 'alerts@example.com'
  smtp_auth_username: 'alerts@example.com'
  smtp_auth_password: 'app-password'

receivers:
- name: 'email-alerts'
  email_configs:
  - to: 'admin@example.com'
    subject: 'Alert: {{ .GroupLabels.alertname }}'
    body: |
      {{ range .Alerts }}
      Alert: {{ .Annotations.summary }}
      {{ end }}
```

### ğŸ” ValidaÃ§Ã£o de ConfiguraÃ§Ã£o

#### âœ… Usando amtool
```bash
# Validar configuraÃ§Ã£o
amtool config check alertmanager.yml

# Mostrar configuraÃ§Ã£o processada
amtool config show --alertmanager.url=http://localhost:9093

# Testar roteamento
amtool config routes test \
  --config.file=alertmanager.yml \
  --tree \
  severity=critical alertname=DatabaseDown
```

#### ğŸ§ª Teste de Templates
```bash
# Testar template especÃ­fico
amtool template test \
  --template.file=templates/email.tmpl \
  --template.name=email.subject \
  --template.data-file=test-alert.json

# Arquivo de teste (test-alert.json)
{
  "Status": "firing",
  "GroupLabels": {"alertname": "TestAlert"},
  "CommonLabels": {"severity": "warning"},
  "Alerts": [{
    "Status": "firing",
    "Labels": {"instance": "localhost:9090"},
    "Annotations": {"summary": "Test alert"}
  }]
}
```

---

## 5. PROBLEMAS DE CONECTIVIDADE

### ğŸŒ DiagnÃ³stico de Rede

#### ğŸ” Testes de Conectividade
```bash
# Testar conectividade com Prometheus
curl -s http://prometheus:9090/api/v1/query?query=up

# Testar webhook
curl -X POST http://webhook.example.com/alerts \
  -H "Content-Type: application/json" \
  -d '[{"status":"firing","labels":{"alertname":"test"}}]'

# Testar SMTP
telnet smtp.gmail.com 587

# Testar Slack webhook
curl -X POST https://hooks.slack.com/services/YOUR/WEBHOOK/URL \
  -H "Content-Type: application/json" \
  -d '{"text":"Test message"}'
```

#### ğŸ³ Problemas Docker
```bash
# Verificar rede Docker
docker network ls
docker network inspect observability-stack-docker_default

# Testar conectividade entre containers
docker exec alertmanager ping prometheus
docker exec alertmanager nslookup prometheus

# Verificar portas expostas
docker port alertmanager
netstat -tlnp | grep 9093
```

### ğŸ”§ ResoluÃ§Ã£o de Problemas

#### ğŸŒ Proxy e Firewall
```bash
# Verificar variÃ¡veis de proxy
echo $HTTP_PROXY
echo $HTTPS_PROXY
echo $NO_PROXY

# Testar sem proxy
unset HTTP_PROXY HTTPS_PROXY
curl -s http://webhook.example.com/test

# Verificar firewall (Linux)
sudo iptables -L
sudo ufw status

# Verificar firewall (Windows)
netsh advfirewall show allprofiles
```

---

## 6. PROBLEMAS DE NOTIFICAÃ‡ÃƒO

### ğŸ“§ Email

#### âŒ Problemas Comuns
```yaml
# Problema: AutenticaÃ§Ã£o SMTP
global:
  smtp_smarthost: 'smtp.gmail.com:587'
  smtp_from: 'alerts@example.com'
  # âŒ Faltando autenticaÃ§Ã£o

# SoluÃ§Ã£o: Adicionar credenciais
global:
  smtp_smarthost: 'smtp.gmail.com:587'
  smtp_from: 'alerts@example.com'
  smtp_auth_username: 'alerts@example.com'
  smtp_auth_password: 'app-password'  # Use App Password, nÃ£o senha normal
  smtp_require_tls: true
```

#### ğŸ” Debug de Email
```bash
# Testar SMTP manualmente
openssl s_client -connect smtp.gmail.com:587 -starttls smtp

# Logs especÃ­ficos de email
docker-compose logs alertmanager | grep -i "email\|smtp"

# Verificar configuraÃ§Ã£o TLS
curl -v --ssl smtp://smtp.gmail.com:587
```

### ğŸ’¬ Slack

#### âŒ Problemas Comuns
```yaml
# Problema: URL de webhook invÃ¡lida
receivers:
- name: 'slack-alerts'
  slack_configs:
  - api_url: 'https://hooks.slack.com/invalid-url'  # âŒ URL incorreta

# SoluÃ§Ã£o: URL correta e configuraÃ§Ã£o completa
receivers:
- name: 'slack-alerts'
  slack_configs:
  - api_url: 'https://hooks.slack.com/services/T00000000/B00000000/XXXXXXXXXXXXXXXXXXXXXXXX'
    channel: '#alerts'
    username: 'Alertmanager'
    title: 'Alert: {{ .GroupLabels.alertname }}'
    text: |
      {{ range .Alerts }}
      *Alert:* {{ .Annotations.summary }}
      *Severity:* {{ .Labels.severity }}
      {{ end }}
```

#### ğŸ” Debug de Slack
```bash
# Testar webhook manualmente
curl -X POST https://hooks.slack.com/services/YOUR/WEBHOOK/URL \
  -H "Content-Type: application/json" \
  -d '{
    "channel": "#alerts",
    "username": "Test",
    "text": "Test message from curl"
  }'

# Verificar resposta do Slack
curl -v -X POST https://hooks.slack.com/services/YOUR/WEBHOOK/URL \
  -H "Content-Type: application/json" \
  -d '{"text":"test"}' 2>&1 | grep -E "(HTTP|ok|invalid)"
```

### ğŸ”— Webhook

#### âŒ Problemas Comuns
```bash
# Problema: Endpoint nÃ£o responde
curl -X POST http://webhook.example.com/alerts
# curl: (7) Failed to connect to webhook.example.com port 80: Connection refused

# DiagnÃ³stico
# 1. Verificar se o serviÃ§o estÃ¡ rodando
ping webhook.example.com
nslookup webhook.example.com

# 2. Verificar porta
telnet webhook.example.com 80

# 3. Testar com timeout
curl --connect-timeout 10 -X POST http://webhook.example.com/alerts
```

---

## 7. PROBLEMAS DE PERFORMANCE

### ğŸ“Š IdentificaÃ§Ã£o de Gargalos

#### ğŸ¯ MÃ©tricas de Performance
```promql
# LatÃªncia de notificaÃ§Ãµes
histogram_quantile(0.95, 
  rate(alertmanager_notification_latency_seconds_bucket[5m])
)

# Uso de memÃ³ria
process_resident_memory_bytes{job="alertmanager"}

# Uso de CPU
rate(process_cpu_seconds_total{job="alertmanager"}[5m])

# Alertas em fila
alertmanager_alerts_received_total - alertmanager_alerts_processed_total
```

#### ğŸ” AnÃ¡lise de Logs
```bash
# NotificaÃ§Ãµes lentas
docker-compose logs alertmanager | \
  grep "notification_latency" | \
  grep -E "[5-9][0-9]{3}ms|[0-9]+s"

# Timeouts
docker-compose logs alertmanager | grep -i timeout

# Erros de memÃ³ria
docker-compose logs alertmanager | grep -i "out of memory\|oom"
```

### âš¡ OtimizaÃ§Ãµes

#### ğŸ”§ ConfiguraÃ§Ã£o de Performance
```yaml
# alertmanager.yml - OtimizaÃ§Ãµes
global:
  # Reduzir timeouts para falhas rÃ¡pidas
  smtp_timeout: 30s
  slack_api_url_timeout: 10s
  
route:
  # Agrupar mais alertas para reduzir notificaÃ§Ãµes
  group_wait: 30s
  group_interval: 5m
  repeat_interval: 12h
  
  # Agrupar por mais labels
  group_by: ['alertname', 'cluster', 'service']

receivers:
- name: 'optimized-webhook'
  webhook_configs:
  - url: 'http://webhook.example.com/alerts'
    # Reduzir timeout
    timeout: 10s
    # NÃ£o enviar alertas resolvidos se nÃ£o necessÃ¡rio
    send_resolved: false
```

#### ğŸ³ Docker Otimizado
```yaml
# compose.yml - Recursos otimizados
services:
  alertmanager:
    image: prom/alertmanager:latest
    deploy:
      resources:
        limits:
          memory: 512M
          cpus: '0.5'
        reservations:
          memory: 256M
          cpus: '0.25'
    # Usar volume para persistÃªncia
    volumes:
      - alertmanager-data:/alertmanager
    # Configurar healthcheck
    healthcheck:
      test: ["CMD", "wget", "--quiet", "--tries=1", "--spider", "http://localhost:9093/-/healthy"]
      interval: 30s
      timeout: 10s
      retries: 3

volumes:
  alertmanager-data:
```

---

## 8. FERRAMENTAS DE DIAGNÃ“STICO

### ğŸ› ï¸ amtool

#### ğŸ“‹ Comandos Essenciais
```bash
# Status geral
amtool --alertmanager.url=http://localhost:9093 status

# Listar alertas
amtool --alertmanager.url=http://localhost:9093 alert query

# Alertas por severity
amtool alert query severity=critical

# Silences ativos
amtool silence query

# ConfiguraÃ§Ã£o atual
amtool config show

# Testar roteamento
amtool config routes test severity=critical alertname=DatabaseDown
```

#### ğŸ§ª SimulaÃ§Ã£o de Alertas
```bash
# Criar alerta de teste
amtool alert add \
  alertname="TestAlert" \
  severity="warning" \
  instance="localhost:9090" \
  summary="Alert de teste"

# Verificar se foi processado
amtool alert query alertname="TestAlert"

# Criar silence para teste
amtool silence add \
  alertname="TestAlert" \
  --duration="1h" \
  --comment="Teste de silence"
```

### ğŸ” Scripts de DiagnÃ³stico

#### ğŸ©º Health Check Completo
```bash
#!/bin/bash
# alertmanager-health-check.sh

AM_URL="http://localhost:9093"
ERRORS=0

echo "ğŸ” Alertmanager Health Check"
echo "================================"

# 1. Verificar se estÃ¡ rodando
echo -n "ğŸ“¡ Conectividade: "
if curl -s "$AM_URL/-/healthy" >/dev/null; then
    echo "âœ… OK"
else
    echo "âŒ FALHA - Alertmanager nÃ£o estÃ¡ acessÃ­vel"
    ((ERRORS++))
fi

# 2. Verificar configuraÃ§Ã£o
echo -n "âš™ï¸  ConfiguraÃ§Ã£o: "
if amtool --alertmanager.url="$AM_URL" config show >/dev/null 2>&1; then
    echo "âœ… OK"
else
    echo "âŒ FALHA - ConfiguraÃ§Ã£o invÃ¡lida"
    ((ERRORS++))
fi

# 3. Verificar alertas
echo -n "ğŸš¨ Alertas ativos: "
ALERT_COUNT=$(amtool --alertmanager.url="$AM_URL" alert query --output=json 2>/dev/null | jq '. | length' 2>/dev/null || echo "0")
echo "$ALERT_COUNT alertas"

# 4. Verificar silences
echo -n "ğŸ”‡ Silences ativos: "
SILENCE_COUNT=$(amtool --alertmanager.url="$AM_URL" silence query --output=json 2>/dev/null | jq '. | length' 2>/dev/null || echo "0")
echo "$SILENCE_COUNT silences"

# 5. Verificar mÃ©tricas
echo -n "ğŸ“Š MÃ©tricas: "
if curl -s "$AM_URL/metrics" | grep -q "alertmanager_build_info"; then
    echo "âœ… OK"
else
    echo "âŒ FALHA - MÃ©tricas nÃ£o disponÃ­veis"
    ((ERRORS++))
fi

echo "================================"
if [ $ERRORS -eq 0 ]; then
    echo "âœ… Alertmanager estÃ¡ saudÃ¡vel!"
    exit 0
else
    echo "âŒ Encontrados $ERRORS problemas"
    exit 1
fi
```

#### ğŸ“Š Monitor de Performance
```bash
#!/bin/bash
# alertmanager-performance.sh

AM_URL="http://localhost:9093"

echo "ğŸ“Š Alertmanager Performance Monitor"
echo "==================================="

while true; do
    # Coletar mÃ©tricas
    METRICS=$(curl -s "$AM_URL/metrics")
    
    # Alertas recebidos por minuto
    ALERTS_RATE=$(echo "$METRICS" | grep "alertmanager_alerts_received_total" | tail -1 | awk '{print $2}')
    
    # NotificaÃ§Ãµes enviadas por minuto
    NOTIFICATIONS_RATE=$(echo "$METRICS" | grep "alertmanager_notifications_total" | tail -1 | awk '{print $2}')
    
    # NotificaÃ§Ãµes falhadas
    NOTIFICATIONS_FAILED=$(echo "$METRICS" | grep "alertmanager_notifications_failed_total" | tail -1 | awk '{print $2}')
    
    # Uso de memÃ³ria
    MEMORY_USAGE=$(echo "$METRICS" | grep "process_resident_memory_bytes" | awk '{print $2}')
    MEMORY_MB=$((MEMORY_USAGE / 1024 / 1024))
    
    # Exibir resultados
    clear
    echo "ğŸ“Š Alertmanager Performance - $(date)"
    echo "====================================="
    echo "ğŸš¨ Alertas recebidos: $ALERTS_RATE"
    echo "ğŸ“¤ NotificaÃ§Ãµes enviadas: $NOTIFICATIONS_RATE"
    echo "âŒ NotificaÃ§Ãµes falhadas: $NOTIFICATIONS_FAILED"
    echo "ğŸ’¾ Uso de memÃ³ria: ${MEMORY_MB}MB"
    
    # Calcular taxa de sucesso
    if [ "$NOTIFICATIONS_RATE" -gt 0 ]; then
        SUCCESS_RATE=$(echo "scale=2; (($NOTIFICATIONS_RATE - $NOTIFICATIONS_FAILED) / $NOTIFICATIONS_RATE) * 100" | bc)
        echo "âœ… Taxa de sucesso: ${SUCCESS_RATE}%"
    fi
    
    sleep 5
done
```

---

## 9. CENÃRIOS COMUNS

### ğŸš¨ "Alertas nÃ£o estÃ£o sendo enviados"

#### ğŸ” DiagnÃ³stico
```bash
# 1. Verificar se alertas estÃ£o chegando
amtool alert query

# 2. Verificar roteamento
amtool config routes test severity=critical alertname=DatabaseDown

# 3. Verificar logs de notificaÃ§Ã£o
docker-compose logs alertmanager | grep -E "(notification|notify)"

# 4. Testar receiver manualmente
curl -X POST http://webhook.example.com/test
```

#### âœ… SoluÃ§Ãµes
```yaml
# Problema comum: Roteamento incorreto
route:
  default_receiver: 'null'  # âŒ Receiver que nÃ£o existe
  
# SoluÃ§Ã£o: Receiver vÃ¡lido
route:
  default_receiver: 'web.hook'
  
receivers:
- name: 'web.hook'
  webhook_configs:
  - url: 'http://webhook.example.com/alerts'
```

### ğŸ”„ "Muitas notificaÃ§Ãµes duplicadas"

#### ğŸ” DiagnÃ³stico
```bash
# Verificar configuraÃ§Ã£o de agrupamento
amtool config show | grep -A 10 "group_"

# Verificar alertas ativos
amtool alert query --output=json | jq '.[] | {alertname: .labels.alertname, instance: .labels.instance}'
```

#### âœ… SoluÃ§Ãµes
```yaml
# Problema: Agrupamento insuficiente
route:
  group_by: ['alertname']  # âŒ Muito genÃ©rico
  group_wait: 5s          # âŒ Muito rÃ¡pido
  
# SoluÃ§Ã£o: Agrupamento melhor
route:
  group_by: ['alertname', 'cluster', 'service']
  group_wait: 30s
  group_interval: 5m
  repeat_interval: 12h
```

### ğŸŒ "NotificaÃ§Ãµes muito lentas"

#### ğŸ” DiagnÃ³stico
```promql
# Verificar latÃªncia
histogram_quantile(0.95, 
  rate(alertmanager_notification_latency_seconds_bucket[5m])
)

# Verificar timeouts
rate(alertmanager_notifications_failed_total{reason="timeout"}[5m])
```

#### âœ… SoluÃ§Ãµes
```yaml
# Otimizar timeouts
global:
  smtp_timeout: 10s
  
receivers:
- name: 'fast-webhook'
  webhook_configs:
  - url: 'http://fast-webhook.example.com/alerts'
    timeout: 5s
    max_alerts: 10  # Limitar nÃºmero de alertas por request
```

---

## 10. PREVENÃ‡ÃƒO DE PROBLEMAS

### ğŸ›¡ï¸ Monitoramento Proativo

#### ğŸ“Š Alertas para o Alertmanager
```yaml
# prometheus-rules.yml
groups:
- name: alertmanager.rules
  rules:
  # Alertmanager down
  - alert: AlertmanagerDown
    expr: up{job="alertmanager"} == 0
    for: 1m
    labels:
      severity: critical
    annotations:
      summary: "Alertmanager estÃ¡ down"
      
  # Falhas de notificaÃ§Ã£o
  - alert: AlertmanagerNotificationsFailing
    expr: rate(alertmanager_notifications_failed_total[5m]) > 0.1
    for: 5m
    labels:
      severity: warning
    annotations:
      summary: "Alertmanager com falhas de notificaÃ§Ã£o"
      
  # ConfiguraÃ§Ã£o nÃ£o recarregada
  - alert: AlertmanagerConfigNotReloaded
    expr: time() - alertmanager_config_last_reload_success_timestamp_seconds > 3600
    for: 0m
    labels:
      severity: warning
    annotations:
      summary: "ConfiguraÃ§Ã£o do Alertmanager nÃ£o foi recarregada hÃ¡ mais de 1h"
```

### ğŸ§ª Testes Automatizados

#### ğŸ”„ CI/CD Pipeline
```yaml
# .github/workflows/alertmanager-test.yml
name: Test Alertmanager Config

on:
  push:
    paths:
      - 'alertmanager.yml'
      - 'templates/**'

jobs:
  test:
    runs-on: ubuntu-latest
    steps:
    - uses: actions/checkout@v2
    
    - name: Download amtool
      run: |
        wget https://github.com/prometheus/alertmanager/releases/download/v0.25.0/alertmanager-0.25.0.linux-amd64.tar.gz
        tar xzf alertmanager-0.25.0.linux-amd64.tar.gz
        sudo mv alertmanager-0.25.0.linux-amd64/amtool /usr/local/bin/
    
    - name: Validate Config
      run: amtool config check alertmanager.yml
    
    - name: Test Templates
      run: |
        for template in templates/*.tmpl; do
          echo "Testing $template"
          amtool template test \
            --template.file="$template" \
            --template.data-file=tests/test-alert.json
        done
    
    - name: Test Routing
      run: |
        amtool config routes test \
          --config.file=alertmanager.yml \
          severity=critical alertname=TestAlert
```

### ğŸ“‹ Checklist de ManutenÃ§Ã£o

#### ğŸ—“ï¸ Semanal
- [ ] Verificar logs de erro
- [ ] Revisar mÃ©tricas de performance
- [ ] Testar notificaÃ§Ãµes crÃ­ticas
- [ ] Verificar espaÃ§o em disco

#### ğŸ—“ï¸ Mensal
- [ ] Atualizar versÃ£o do Alertmanager
- [ ] Revisar configuraÃ§Ã£o de receivers
- [ ] Limpar silences expirados
- [ ] Backup da configuraÃ§Ã£o

#### ğŸ—“ï¸ Trimestral
- [ ] Revisar templates de notificaÃ§Ã£o
- [ ] Otimizar regras de roteamento
- [ ] Treinar equipe em novos recursos
- [ ] Documentar mudanÃ§as

---

## ğŸ¯ RESUMO DO MÃ“DULO

### âœ… O que vocÃª aprendeu:

1. **DiagnÃ³stico inicial** - Checklist e verificaÃ§Ãµes bÃ¡sicas
2. **Logs e debugging** - ConfiguraÃ§Ã£o e anÃ¡lise de logs
3. **MÃ©tricas de monitoramento** - MÃ©tricas essenciais e dashboards
4. **Problemas de configuraÃ§Ã£o** - Erros comuns e validaÃ§Ã£o
5. **Problemas de conectividade** - DiagnÃ³stico de rede
6. **Problemas de notificaÃ§Ã£o** - Debug de email, Slack, webhook
7. **Problemas de performance** - IdentificaÃ§Ã£o e otimizaÃ§Ã£o
8. **Ferramentas de diagnÃ³stico** - amtool e scripts personalizados
9. **CenÃ¡rios comuns** - Problemas frequentes e soluÃ§Ãµes
10. **PrevenÃ§Ã£o de problemas** - Monitoramento proativo e testes

### ğŸ”§ Principais conceitos:
- **DiagnÃ³stico sistemÃ¡tico** - Abordagem estruturada para resolver problemas
- **Logs estruturados** - AnÃ¡lise eficiente de logs JSON
- **MÃ©tricas de saÃºde** - Monitoramento proativo do Alertmanager
- **ValidaÃ§Ã£o automatizada** - Testes de configuraÃ§Ã£o e templates
- **Performance tuning** - OtimizaÃ§Ã£o de recursos e latÃªncia

### ğŸš€ PrÃ³ximos Passos

Agora que vocÃª sabe resolver problemas, vamos aprender sobre **integraÃ§Ã£o avanÃ§ada**:

**PrÃ³ximo mÃ³dulo:** [09-integracao-avancada.md](09-integracao-avancada.md) - IntegraÃ§Ã£o com outras ferramentas

---

## ğŸ”— Links Relacionados

- **[Anterior: Templates](07-templates.md)**
- **[PrÃ³ximo: IntegraÃ§Ã£o AvanÃ§ada](09-integracao-avancada.md)**
- **[Voltar ao Ãndice](README.md)**