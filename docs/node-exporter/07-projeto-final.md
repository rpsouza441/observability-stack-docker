# M√≥dulo 07: Projeto Final - Monitoramento Completo de Infraestrutura

Este m√≥dulo apresenta um projeto pr√°tico completo que integra todos os conceitos aprendidos nos m√≥dulos anteriores, implementando uma solu√ß√£o de monitoramento de infraestrutura robusta e escal√°vel.

## üéØ Objetivo do Projeto

Implementar uma solu√ß√£o completa de monitoramento de infraestrutura usando Node Exporter, incluindo:
- Monitoramento multi-servidor
- Dashboards personalizados
- Sistema de alertas avan√ßado
- Automa√ß√£o e orquestra√ß√£o
- Documenta√ß√£o e procedimentos operacionais

## üèóÔ∏è Arquitetura da Solu√ß√£o

```mermaid
graph TB
    subgraph "Infraestrutura Monitorada"
        WEB1[Web Server 1<br/>Node Exporter]
        WEB2[Web Server 2<br/>Node Exporter]
        DB1[Database Server<br/>Node Exporter]
        LB1[Load Balancer<br/>Node Exporter]
    end
    
    subgraph "Stack de Monitoramento"
        PROM[Prometheus<br/>Service Discovery]
        GRAF[Grafana<br/>Dashboards]
        ALERT[Alertmanager<br/>Notifications]
    end
    
    subgraph "Notifica√ß√µes"
        SLACK[Slack]
        EMAIL[Email]
        WEBHOOK[Webhook]
    end
    
    WEB1 --> PROM
    WEB2 --> PROM
    DB1 --> PROM
    LB1 --> PROM
    
    PROM --> GRAF
    PROM --> ALERT
    
    ALERT --> SLACK
    ALERT --> EMAIL
    ALERT --> WEBHOOK
```

## üìã Estrutura do Projeto

### Organiza√ß√£o de Arquivos

```bash
#!/bin/bash
# setup-project-structure.sh

PROJECT_ROOT="/opt/infrastructure-monitoring"

echo "üèóÔ∏è Criando estrutura do projeto..."

# Criar diret√≥rios principais
mkdir -p "$PROJECT_ROOT"/{config,scripts,dashboards,alerts,docs,logs,backup}

# Subdiret√≥rios de configura√ß√£o
mkdir -p "$PROJECT_ROOT/config"/{prometheus,grafana,alertmanager,node-exporter}

# Subdiret√≥rios de scripts
mkdir -p "$PROJECT_ROOT/scripts"/{deployment,monitoring,maintenance,backup}

# Subdiret√≥rios de dashboards
mkdir -p "$PROJECT_ROOT/dashboards"/{infrastructure,applications,security,custom}

# Subdiret√≥rios de alertas
mkdir -p "$PROJECT_ROOT/alerts"/{rules,templates,integrations}

# Subdiret√≥rios de documenta√ß√£o
mkdir -p "$PROJECT_ROOT/docs"/{runbooks,procedures,architecture}

echo "‚úÖ Estrutura do projeto criada em: $PROJECT_ROOT"

# Criar arquivo de invent√°rio
cat > "$PROJECT_ROOT/config/inventory.yml" << 'EOF'
# Invent√°rio de Servidores
servers:
  web_servers:
    - name: web-01
      ip: 192.168.1.10
      role: frontend
      environment: production
      node_exporter_port: 9100
    - name: web-02
      ip: 192.168.1.11
      role: frontend
      environment: production
      node_exporter_port: 9100
  
  database_servers:
    - name: db-01
      ip: 192.168.1.20
      role: database
      environment: production
      node_exporter_port: 9100
  
  load_balancers:
    - name: lb-01
      ip: 192.168.1.5
      role: loadbalancer
      environment: production
      node_exporter_port: 9100
  
  monitoring_servers:
    - name: monitor-01
      ip: 192.168.1.100
      role: monitoring
      environment: production
      services:
        - prometheus
        - grafana
        - alertmanager
EOF

echo "üìã Invent√°rio de servidores criado"
```

## üöÄ Implementa√ß√£o Completa

### 1. Deploy Automatizado do Node Exporter

```bash
#!/bin/bash
# deploy-node-exporter-fleet.sh

PROJECT_ROOT="/opt/infrastructure-monitoring"
INVENTORY_FILE="$PROJECT_ROOT/config/inventory.yml"
SSH_KEY="~/.ssh/infrastructure_key"
SSH_USER="admin"

echo "üöÄ Deploy Automatizado do Node Exporter"
echo "======================================"

# Fun√ß√£o para extrair IPs do invent√°rio
get_server_ips() {
    python3 << 'EOF'
import yaml
import sys

with open('/opt/infrastructure-monitoring/config/inventory.yml', 'r') as f:
    inventory = yaml.safe_load(f)

for category in inventory['servers']:
    for server in inventory['servers'][category]:
        print(f"{server['ip']} {server['name']} {server['role']}")
EOF
}

# Fun√ß√£o para instalar Node Exporter em um servidor
install_node_exporter() {
    local server_ip=$1
    local server_name=$2
    local server_role=$3
    
    echo "üì¶ Instalando Node Exporter em $server_name ($server_ip)..."
    
    # Script de instala√ß√£o remota
    ssh -i "$SSH_KEY" "$SSH_USER@$server_ip" << 'REMOTE_SCRIPT'
        # Baixar e instalar Node Exporter
        cd /tmp
        wget https://github.com/prometheus/node_exporter/releases/download/v1.6.1/node_exporter-1.6.1.linux-amd64.tar.gz
        tar xvfz node_exporter-1.6.1.linux-amd64.tar.gz
        
        # Criar usu√°rio
        sudo useradd --no-create-home --shell /bin/false node_exporter
        
        # Instalar bin√°rio
        sudo cp node_exporter-1.6.1.linux-amd64/node_exporter /usr/local/bin/
        sudo chown node_exporter:node_exporter /usr/local/bin/node_exporter
        
        # Criar diret√≥rios
        sudo mkdir -p /var/lib/node_exporter/textfile_collector
        sudo chown -R node_exporter:node_exporter /var/lib/node_exporter
        
        # Criar configura√ß√£o systemd
        sudo tee /etc/systemd/system/node_exporter.service > /dev/null << 'EOF'
[Unit]
Description=Node Exporter
Wants=network-online.target
After=network-online.target

[Service]
User=node_exporter
Group=node_exporter
Type=simple
ExecStart=/usr/local/bin/node_exporter \
    --web.listen-address=:9100 \
    --web.telemetry-path=/metrics \
    --collector.textfile.directory=/var/lib/node_exporter/textfile_collector \
    --collector.filesystem.ignored-mount-points="^/(dev|proc|sys|var/lib/docker/.+)(\$|/)" \
    --collector.filesystem.ignored-fs-types="^(autofs|binfmt_misc|bpf|cgroup2?|configfs|debugfs|devpts|devtmpfs|fusectl|hugetlbfs|iso9660|mqueue|nsfs|overlay|proc|procfs|pstore|rpc_pipefs|securityfs|selinuxfs|squashfs|sysfs|tracefs)(\$|/)" \
    --collector.netdev.ignored-devices="^(veth.*|docker.*|br-.*)\$"

SyslogIdentifier=node_exporter
Restart=always
RestartSec=5

[Install]
WantedBy=multi-user.target
EOF
        
        # Habilitar e iniciar servi√ßo
        sudo systemctl daemon-reload
        sudo systemctl enable node_exporter
        sudo systemctl start node_exporter
        
        # Verificar status
        sudo systemctl status node_exporter --no-pager
        
        # Cleanup
        rm -rf /tmp/node_exporter-*
REMOTE_SCRIPT
    
    if [ $? -eq 0 ]; then
        echo "‚úÖ Node Exporter instalado com sucesso em $server_name"
    else
        echo "‚ùå Falha na instala√ß√£o em $server_name"
    fi
}

# Fun√ß√£o para configurar m√©tricas customizadas por role
setup_custom_metrics() {
    local server_ip=$1
    local server_name=$2
    local server_role=$3
    
    echo "üîß Configurando m√©tricas customizadas para $server_name ($server_role)..."
    
    case $server_role in
        "frontend")
            # M√©tricas espec√≠ficas para servidores web
            ssh -i "$SSH_KEY" "$SSH_USER@$server_ip" << 'WEB_METRICS'
                # Script para m√©tricas de servidor web
                sudo tee /var/lib/node_exporter/textfile_collector/web_metrics.sh > /dev/null << 'EOF'
#!/bin/bash
# M√©tricas customizadas para servidor web

# Conex√µes HTTP
http_connections=$(netstat -an | grep :80 | grep ESTABLISHED | wc -l)
echo "web_http_connections $http_connections" > /var/lib/node_exporter/textfile_collector/web_metrics.prom.tmp

# Conex√µes HTTPS
https_connections=$(netstat -an | grep :443 | grep ESTABLISHED | wc -l)
echo "web_https_connections $https_connections" >> /var/lib/node_exporter/textfile_collector/web_metrics.prom.tmp

# Processos Apache/Nginx
web_processes=$(pgrep -c "apache2|nginx|httpd")
echo "web_processes_count $web_processes" >> /var/lib/node_exporter/textfile_collector/web_metrics.prom.tmp

# Mover arquivo tempor√°rio
mv /var/lib/node_exporter/textfile_collector/web_metrics.prom.tmp /var/lib/node_exporter/textfile_collector/web_metrics.prom
EOF
                
                sudo chmod +x /var/lib/node_exporter/textfile_collector/web_metrics.sh
                sudo chown node_exporter:node_exporter /var/lib/node_exporter/textfile_collector/web_metrics.sh
                
                # Adicionar ao cron
                echo "*/1 * * * * /var/lib/node_exporter/textfile_collector/web_metrics.sh" | sudo crontab -u node_exporter -
WEB_METRICS
            ;;
        "database")
            # M√©tricas espec√≠ficas para servidores de banco
            ssh -i "$SSH_KEY" "$SSH_USER@$server_ip" << 'DB_METRICS'
                sudo tee /var/lib/node_exporter/textfile_collector/db_metrics.sh > /dev/null << 'EOF'
#!/bin/bash
# M√©tricas customizadas para servidor de banco

# Conex√µes MySQL/PostgreSQL
db_connections=$(netstat -an | grep :3306 | grep ESTABLISHED | wc -l)
echo "db_mysql_connections $db_connections" > /var/lib/node_exporter/textfile_collector/db_metrics.prom.tmp

pg_connections=$(netstat -an | grep :5432 | grep ESTABLISHED | wc -l)
echo "db_postgresql_connections $pg_connections" >> /var/lib/node_exporter/textfile_collector/db_metrics.prom.tmp

# Processos de banco
db_processes=$(pgrep -c "mysqld|postgres")
echo "db_processes_count $db_processes" >> /var/lib/node_exporter/textfile_collector/db_metrics.prom.tmp

# Tamanho dos logs
if [ -d "/var/log/mysql" ]; then
    mysql_log_size=$(du -sb /var/log/mysql 2>/dev/null | cut -f1 || echo 0)
    echo "db_mysql_log_size_bytes $mysql_log_size" >> /var/lib/node_exporter/textfile_collector/db_metrics.prom.tmp
fi

mv /var/lib/node_exporter/textfile_collector/db_metrics.prom.tmp /var/lib/node_exporter/textfile_collector/db_metrics.prom
EOF
                
                sudo chmod +x /var/lib/node_exporter/textfile_collector/db_metrics.sh
                sudo chown node_exporter:node_exporter /var/lib/node_exporter/textfile_collector/db_metrics.sh
                echo "*/2 * * * * /var/lib/node_exporter/textfile_collector/db_metrics.sh" | sudo crontab -u node_exporter -
DB_METRICS
            ;;
        "loadbalancer")
            # M√©tricas espec√≠ficas para load balancers
            ssh -i "$SSH_KEY" "$SSH_USER@$server_ip" << 'LB_METRICS'
                sudo tee /var/lib/node_exporter/textfile_collector/lb_metrics.sh > /dev/null << 'EOF'
#!/bin/bash
# M√©tricas customizadas para load balancer

# Conex√µes totais
total_connections=$(netstat -an | grep ESTABLISHED | wc -l)
echo "lb_total_connections $total_connections" > /var/lib/node_exporter/textfile_collector/lb_metrics.prom.tmp

# Processos HAProxy/Nginx
lb_processes=$(pgrep -c "haproxy|nginx")
echo "lb_processes_count $lb_processes" >> /var/lib/node_exporter/textfile_collector/lb_metrics.prom.tmp

# Bandwidth (aproximado)
rx_bytes=$(cat /proc/net/dev | grep eth0 | awk '{print $2}')
tx_bytes=$(cat /proc/net/dev | grep eth0 | awk '{print $10}')
echo "lb_rx_bytes_total $rx_bytes" >> /var/lib/node_exporter/textfile_collector/lb_metrics.prom.tmp
echo "lb_tx_bytes_total $tx_bytes" >> /var/lib/node_exporter/textfile_collector/lb_metrics.prom.tmp

mv /var/lib/node_exporter/textfile_collector/lb_metrics.prom.tmp /var/lib/node_exporter/textfile_collector/lb_metrics.prom
EOF
                
                sudo chmod +x /var/lib/node_exporter/textfile_collector/lb_metrics.sh
                sudo chown node_exporter:node_exporter /var/lib/node_exporter/textfile_collector/lb_metrics.sh
                echo "*/1 * * * * /var/lib/node_exporter/textfile_collector/lb_metrics.sh" | sudo crontab -u node_exporter -
LB_METRICS
            ;;
    esac
    
    echo "‚úÖ M√©tricas customizadas configuradas para $server_name"
}

# Executar deploy em todos os servidores
echo "üìã Lendo invent√°rio de servidores..."

get_server_ips | while read ip name role; do
    echo "\nüéØ Processando servidor: $name ($ip) - Role: $role"
    
    # Testar conectividade
    if ssh -i "$SSH_KEY" -o ConnectTimeout=5 "$SSH_USER@$ip" "echo 'Conectado'" > /dev/null 2>&1; then
        echo "‚úÖ Conectividade OK"
        
        # Instalar Node Exporter
        install_node_exporter "$ip" "$name" "$role"
        
        # Configurar m√©tricas customizadas
        setup_custom_metrics "$ip" "$name" "$role"
        
        # Verificar se est√° funcionando
        if ssh -i "$SSH_KEY" "$SSH_USER@$ip" "curl -s http://localhost:9100/metrics | head -5" > /dev/null 2>&1; then
            echo "‚úÖ Node Exporter funcionando em $name"
        else
            echo "‚ùå Node Exporter n√£o est√° respondendo em $name"
        fi
    else
        echo "‚ùå N√£o foi poss√≠vel conectar em $ip"
    fi
done

echo "\nüéâ Deploy do Node Exporter conclu√≠do!"
```

### 2. Configura√ß√£o do Prometheus com Service Discovery

```yaml
# prometheus-infrastructure.yml
global:
  scrape_interval: 15s
  evaluation_interval: 15s
  external_labels:
    cluster: 'infrastructure-monitoring'
    environment: 'production'

rule_files:
  - "/etc/prometheus/rules/*.yml"

alerting:
  alertmanagers:
    - static_configs:
        - targets:
          - alertmanager:9093

scrape_configs:
  # Node Exporter - Web Servers
  - job_name: 'node-exporter-web'
    static_configs:
      - targets:
        - '192.168.1.10:9100'  # web-01
        - '192.168.1.11:9100'  # web-02
    relabel_configs:
      - source_labels: [__address__]
        regex: '192.168.1.10:9100'
        target_label: instance
        replacement: 'web-01'
      - source_labels: [__address__]
        regex: '192.168.1.11:9100'
        target_label: instance
        replacement: 'web-02'
      - target_label: role
        replacement: 'frontend'
      - target_label: environment
        replacement: 'production'
    metric_relabel_configs:
      - source_labels: [__name__]
        regex: 'node_network_.*'
        target_label: __tmp_network
        replacement: 'true'
      - source_labels: [device]
        regex: 'veth.*|docker.*|br-.*'
        action: drop

  # Node Exporter - Database Servers
  - job_name: 'node-exporter-database'
    static_configs:
      - targets:
        - '192.168.1.20:9100'  # db-01
    relabel_configs:
      - source_labels: [__address__]
        regex: '192.168.1.20:9100'
        target_label: instance
        replacement: 'db-01'
      - target_label: role
        replacement: 'database'
      - target_label: environment
        replacement: 'production'
    scrape_interval: 10s  # Mais frequente para DB

  # Node Exporter - Load Balancers
  - job_name: 'node-exporter-loadbalancer'
    static_configs:
      - targets:
        - '192.168.1.5:9100'   # lb-01
    relabel_configs:
      - source_labels: [__address__]
        regex: '192.168.1.5:9100'
        target_label: instance
        replacement: 'lb-01'
      - target_label: role
        replacement: 'loadbalancer'
      - target_label: environment
        replacement: 'production'
    scrape_interval: 5s   # Mais frequente para LB

  # File-based Service Discovery (para expans√£o futura)
  - job_name: 'node-exporter-dynamic'
    file_sd_configs:
      - files:
        - '/etc/prometheus/targets/*.json'
        refresh_interval: 30s
    relabel_configs:
      - source_labels: [__meta_filepath]
        target_label: __tmp_filepath
      - source_labels: [__tmp_filepath]
        regex: '.*/([^/]+)\.json'
        target_label: service_group
        replacement: '${1}'

  # Prometheus self-monitoring
  - job_name: 'prometheus'
    static_configs:
      - targets: ['localhost:9090']
    relabel_configs:
      - target_label: role
        replacement: 'monitoring'

# Recording rules para otimiza√ß√£o
recording_rules:
  - name: infrastructure.rules
    rules:
      # CPU Usage por servidor
      - record: instance:node_cpu_utilization:rate5m
        expr: |
          100 - (
            avg by (instance, role) (
              irate(node_cpu_seconds_total{mode="idle"}[5m])
            ) * 100
          )
      
      # Memory Usage por servidor
      - record: instance:node_memory_utilization:ratio
        expr: |
          (
            node_memory_MemTotal_bytes - node_memory_MemAvailable_bytes
          ) / node_memory_MemTotal_bytes * 100
      
      # Disk Usage por servidor
      - record: instance:node_disk_utilization:ratio
        expr: |
          100 - (
            node_filesystem_avail_bytes{fstype!="tmpfs"} / 
            node_filesystem_size_bytes{fstype!="tmpfs"} * 100
          )
      
      # Network Traffic por servidor
      - record: instance:node_network_transmit_bytes:rate5m
        expr: |
          sum by (instance, role) (
            irate(node_network_transmit_bytes_total{device!~"veth.*|docker.*|br-.*"}[5m])
          )
      
      - record: instance:node_network_receive_bytes:rate5m
        expr: |
          sum by (instance, role) (
            irate(node_network_receive_bytes_total{device!~"veth.*|docker.*|br-.*"}[5m])
          )
```

### 3. Sistema de Alertas Avan√ßado

```yaml
# infrastructure-alerts.yml
groups:
  - name: infrastructure.critical
    rules:
      # Servidor Down
      - alert: ServerDown
        expr: up{job=~"node-exporter-.*"} == 0
        for: 1m
        labels:
          severity: critical
          team: infrastructure
        annotations:
          summary: "Servidor {{ $labels.instance }} est√° down"
          description: |
            O servidor {{ $labels.instance }} ({{ $labels.role }}) n√£o est√° respondendo h√° mais de 1 minuto.
            
            Detalhes:
            - Instance: {{ $labels.instance }}
            - Role: {{ $labels.role }}
            - Job: {{ $labels.job }}
            - Environment: {{ $labels.environment }}
          
          runbook_url: "https://wiki.company.com/runbooks/server-down"

      # CPU Cr√≠tico
      - alert: HighCPUUsage
        expr: instance:node_cpu_utilization:rate5m > 90
        for: 5m
        labels:
          severity: critical
          team: infrastructure
        annotations:
          summary: "Alto uso de CPU em {{ $labels.instance }}"
          description: |
            CPU usage est√° em {{ $value | humanizePercentage }} no servidor {{ $labels.instance }}.
            
            Threshold: 90%
            Dura√ß√£o: 5 minutos
            Role: {{ $labels.role }}
          
          runbook_url: "https://wiki.company.com/runbooks/high-cpu"

      # Mem√≥ria Cr√≠tica
      - alert: HighMemoryUsage
        expr: instance:node_memory_utilization:ratio > 95
        for: 3m
        labels:
          severity: critical
          team: infrastructure
        annotations:
          summary: "Alto uso de mem√≥ria em {{ $labels.instance }}"
          description: |
            Memory usage est√° em {{ $value | humanizePercentage }} no servidor {{ $labels.instance }}.
            
            Threshold: 95%
            Dura√ß√£o: 3 minutos
            Role: {{ $labels.role }}

      # Disco Cr√≠tico
      - alert: HighDiskUsage
        expr: instance:node_disk_utilization:ratio > 90
        for: 2m
        labels:
          severity: critical
          team: infrastructure
        annotations:
          summary: "Alto uso de disco em {{ $labels.instance }}"
          description: |
            Disk usage est√° em {{ $value | humanizePercentage }} no servidor {{ $labels.instance }}.
            
            Filesystem: {{ $labels.mountpoint }}
            Device: {{ $labels.device }}
            Threshold: 90%

  - name: infrastructure.warning
    rules:
      # Load Average Alto
      - alert: HighLoadAverage
        expr: node_load15 / on(instance) count by (instance)(node_cpu_seconds_total{mode="idle"}) > 0.8
        for: 10m
        labels:
          severity: warning
          team: infrastructure
        annotations:
          summary: "Load average alto em {{ $labels.instance }}"
          description: |
            Load average (15min) est√° em {{ $value }} no servidor {{ $labels.instance }}.
            
            Isso indica que o sistema pode estar sobrecarregado.
            Role: {{ $labels.role }}

      # Muitas conex√µes de rede
      - alert: HighNetworkConnections
        expr: node_netstat_Tcp_CurrEstab > 1000
        for: 5m
        labels:
          severity: warning
          team: infrastructure
        annotations:
          summary: "Muitas conex√µes TCP em {{ $labels.instance }}"
          description: |
            N√∫mero de conex√µes TCP estabelecidas: {{ $value }}
            
            Threshold: 1000 conex√µes
            Servidor: {{ $labels.instance }} ({{ $labels.role }})

  - name: infrastructure.application
    rules:
      # M√©tricas espec√≠ficas por role
      - alert: WebServerConnectionsHigh
        expr: web_http_connections + web_https_connections > 500
        for: 5m
        labels:
          severity: warning
          team: frontend
        annotations:
          summary: "Muitas conex√µes HTTP/HTTPS em {{ $labels.instance }}"
          description: |
            Total de conex√µes web: {{ $value }}
            
            HTTP: {{ with query "web_http_connections{instance='" }}{{ . | first | value }}{{ end }}
            HTTPS: {{ with query "web_https_connections{instance='" }}{{ . | first | value }}{{ end }}

      - alert: DatabaseConnectionsHigh
        expr: db_mysql_connections + db_postgresql_connections > 100
        for: 3m
        labels:
          severity: warning
          team: database
        annotations:
          summary: "Muitas conex√µes de banco em {{ $labels.instance }}"
          description: |
            Total de conex√µes de banco: {{ $value }}
            
            MySQL: {{ with query "db_mysql_connections{instance='" }}{{ . | first | value }}{{ end }}
            PostgreSQL: {{ with query "db_postgresql_connections{instance='" }}{{ . | first | value }}{{ end }}

  - name: infrastructure.predictive
    rules:
      # Alertas preditivos
      - alert: DiskWillFillIn4Hours
        expr: |
          predict_linear(node_filesystem_avail_bytes{fstype!="tmpfs"}[1h], 4*3600) < 0
        for: 5m
        labels:
          severity: warning
          team: infrastructure
        annotations:
          summary: "Disco ser√° preenchido em 4 horas em {{ $labels.instance }}"
          description: |
            Baseado na tend√™ncia atual, o disco {{ $labels.mountpoint }} 
            ser√° preenchido completamente em aproximadamente 4 horas.
            
            Servidor: {{ $labels.instance }}
            Filesystem: {{ $labels.mountpoint }}
            Device: {{ $labels.device }}

      - alert: MemoryLeakDetected
        expr: |
          increase(node_memory_MemTotal_bytes - node_memory_MemAvailable_bytes[6h]) > 1073741824
        for: 10m
        labels:
          severity: warning
          team: infrastructure
        annotations:
          summary: "Poss√≠vel vazamento de mem√≥ria em {{ $labels.instance }}"
          description: |
            O uso de mem√≥ria aumentou mais de 1GB nas √∫ltimas 6 horas.
            
            Isso pode indicar um vazamento de mem√≥ria.
            Servidor: {{ $labels.instance }} ({{ $labels.role }})
```

### 4. Dashboards Personalizados

```bash
#!/bin/bash
# create-infrastructure-dashboards.sh

GRAFANA_URL="http://localhost:3000"
GRAFANA_USER="admin"
GRAFANA_PASS="admin"
DASHBOARD_DIR="/opt/infrastructure-monitoring/dashboards"

echo "üìä Criando Dashboards de Infraestrutura"
echo "======================================"

# Fun√ß√£o para importar dashboard
import_dashboard() {
    local dashboard_file=$1
    local dashboard_name=$2
    
    echo "üìà Importando dashboard: $dashboard_name"
    
    curl -X POST \
        -H "Content-Type: application/json" \
        -u "$GRAFANA_USER:$GRAFANA_PASS" \
        -d @"$dashboard_file" \
        "$GRAFANA_URL/api/dashboards/db"
    
    if [ $? -eq 0 ]; then
        echo "‚úÖ Dashboard '$dashboard_name' importado com sucesso"
    else
        echo "‚ùå Falha ao importar dashboard '$dashboard_name'"
    fi
}

# Dashboard 1: Infrastructure Overview
cat > "$DASHBOARD_DIR/infrastructure-overview.json" << 'EOF'
{
  "dashboard": {
    "id": null,
    "title": "Infrastructure Overview",
    "tags": ["infrastructure", "overview"],
    "timezone": "browser",
    "panels": [
      {
        "id": 1,
        "title": "Servers Status",
        "type": "stat",
        "targets": [
          {
            "expr": "count(up{job=~\"node-exporter-.*\"})",
            "legendFormat": "Total Servers"
          },
          {
            "expr": "count(up{job=~\"node-exporter-.*\"} == 1)",
            "legendFormat": "Online Servers"
          },
          {
            "expr": "count(up{job=~\"node-exporter-.*\"} == 0)",
            "legendFormat": "Offline Servers"
          }
        ],
        "gridPos": {"h": 8, "w": 12, "x": 0, "y": 0}
      },
      {
        "id": 2,
        "title": "CPU Usage by Server",
        "type": "timeseries",
        "targets": [
          {
            "expr": "instance:node_cpu_utilization:rate5m",
            "legendFormat": "{{instance}} ({{role}})"
          }
        ],
        "gridPos": {"h": 8, "w": 12, "x": 12, "y": 0}
      },
      {
        "id": 3,
        "title": "Memory Usage by Server",
        "type": "timeseries",
        "targets": [
          {
            "expr": "instance:node_memory_utilization:ratio",
            "legendFormat": "{{instance}} ({{role}})"
          }
        ],
        "gridPos": {"h": 8, "w": 12, "x": 0, "y": 8}
      },
      {
        "id": 4,
        "title": "Disk Usage by Server",
        "type": "timeseries",
        "targets": [
          {
            "expr": "instance:node_disk_utilization:ratio",
            "legendFormat": "{{instance}} {{mountpoint}}"
          }
        ],
        "gridPos": {"h": 8, "w": 12, "x": 12, "y": 8}
      },
      {
        "id": 5,
        "title": "Network Traffic",
        "type": "timeseries",
        "targets": [
          {
            "expr": "instance:node_network_transmit_bytes:rate5m * 8",
            "legendFormat": "{{instance}} TX"
          },
          {
            "expr": "instance:node_network_receive_bytes:rate5m * 8",
            "legendFormat": "{{instance}} RX"
          }
        ],
        "gridPos": {"h": 8, "w": 24, "x": 0, "y": 16}
      }
    ],
    "time": {
      "from": "now-1h",
      "to": "now"
    },
    "refresh": "30s"
  }
}
EOF

# Dashboard 2: Application Specific
cat > "$DASHBOARD_DIR/application-metrics.json" << 'EOF'
{
  "dashboard": {
    "id": null,
    "title": "Application Metrics",
    "tags": ["application", "custom"],
    "timezone": "browser",
    "panels": [
      {
        "id": 1,
        "title": "Web Server Connections",
        "type": "timeseries",
        "targets": [
          {
            "expr": "web_http_connections",
            "legendFormat": "{{instance}} HTTP"
          },
          {
            "expr": "web_https_connections",
            "legendFormat": "{{instance}} HTTPS"
          }
        ],
        "gridPos": {"h": 8, "w": 12, "x": 0, "y": 0}
      },
      {
        "id": 2,
        "title": "Database Connections",
        "type": "timeseries",
        "targets": [
          {
            "expr": "db_mysql_connections",
            "legendFormat": "{{instance}} MySQL"
          },
          {
            "expr": "db_postgresql_connections",
            "legendFormat": "{{instance}} PostgreSQL"
          }
        ],
        "gridPos": {"h": 8, "w": 12, "x": 12, "y": 0}
      },
      {
        "id": 3,
        "title": "Load Balancer Traffic",
        "type": "timeseries",
        "targets": [
          {
            "expr": "rate(lb_rx_bytes_total[5m]) * 8",
            "legendFormat": "{{instance}} RX"
          },
          {
            "expr": "rate(lb_tx_bytes_total[5m]) * 8",
            "legendFormat": "{{instance}} TX"
          }
        ],
        "gridPos": {"h": 8, "w": 24, "x": 0, "y": 8}
      }
    ],
    "time": {
      "from": "now-1h",
      "to": "now"
    },
    "refresh": "15s"
  }
}
EOF

# Dashboard 3: Security Monitoring
cat > "$DASHBOARD_DIR/security-monitoring.json" << 'EOF'
{
  "dashboard": {
    "id": null,
    "title": "Security Monitoring",
    "tags": ["security", "monitoring"],
    "timezone": "browser",
    "panels": [
      {
        "id": 1,
        "title": "Failed Login Attempts",
        "type": "timeseries",
        "targets": [
          {
            "expr": "increase(node_systemd_unit_state{name=\"ssh.service\", state=\"failed\"}[5m])",
            "legendFormat": "{{instance}} SSH Failures"
          }
        ],
        "gridPos": {"h": 8, "w": 12, "x": 0, "y": 0}
      },
      {
        "id": 2,
        "title": "Network Connections by Port",
        "type": "timeseries",
        "targets": [
          {
            "expr": "node_netstat_Tcp_CurrEstab",
            "legendFormat": "{{instance}} TCP Connections"
          }
        ],
        "gridPos": {"h": 8, "w": 12, "x": 12, "y": 0}
      },
      {
        "id": 3,
        "title": "Process Count by Server",
        "type": "timeseries",
        "targets": [
          {
            "expr": "node_procs_running",
            "legendFormat": "{{instance}} Running"
          },
          {
            "expr": "node_procs_blocked",
            "legendFormat": "{{instance}} Blocked"
          }
        ],
        "gridPos": {"h": 8, "w": 24, "x": 0, "y": 8}
      }
    ],
    "time": {
      "from": "now-4h",
      "to": "now"
    },
    "refresh": "1m"
  }
}
EOF

# Importar todos os dashboards
import_dashboard "$DASHBOARD_DIR/infrastructure-overview.json" "Infrastructure Overview"
import_dashboard "$DASHBOARD_DIR/application-metrics.json" "Application Metrics"
import_dashboard "$DASHBOARD_DIR/security-monitoring.json" "Security Monitoring"

echo "\n‚úÖ Todos os dashboards foram criados!"
```

### 5. Automa√ß√£o e Orquestra√ß√£o

```bash
#!/bin/bash
# infrastructure-automation.sh

PROJECT_ROOT="/opt/infrastructure-monitoring"
LOG_DIR="$PROJECT_ROOT/logs"
BACKUP_DIR="$PROJECT_ROOT/backup"

echo "ü§ñ Sistema de Automa√ß√£o de Infraestrutura"
echo "========================================="

# Fun√ß√£o para backup de configura√ß√µes
backup_configurations() {
    echo "üíæ Realizando backup das configura√ß√µes..."
    
    local backup_date=$(date +%Y%m%d_%H%M%S)
    local backup_file="$BACKUP_DIR/config_backup_$backup_date.tar.gz"
    
    tar -czf "$backup_file" \
        /etc/prometheus/ \
        /etc/grafana/ \
        /etc/alertmanager/ \
        "$PROJECT_ROOT/config/" \
        2>/dev/null
    
    if [ $? -eq 0 ]; then
        echo "‚úÖ Backup criado: $backup_file"
        
        # Manter apenas os √∫ltimos 7 backups
        find "$BACKUP_DIR" -name "config_backup_*.tar.gz" -mtime +7 -delete
    else
        echo "‚ùå Falha no backup"
    fi
}

# Fun√ß√£o para verifica√ß√£o de sa√∫de autom√°tica
automated_health_check() {
    echo "üè• Executando verifica√ß√£o de sa√∫de autom√°tica..."
    
    local health_report="$LOG_DIR/health_check_$(date +%Y%m%d_%H%M%S).log"
    
    {
        echo "=== Health Check Report ==="
        echo "Date: $(date)"
        echo "\n=== Prometheus Status ==="
        systemctl status prometheus --no-pager -l
        
        echo "\n=== Grafana Status ==="
        systemctl status grafana-server --no-pager -l
        
        echo "\n=== Alertmanager Status ==="
        systemctl status alertmanager --no-pager -l
        
        echo "\n=== Node Exporter Targets ==="
        curl -s "http://localhost:9090/api/v1/targets" | jq '.data.activeTargets[] | {job: .labels.job, instance: .labels.instance, health: .health}'
        
        echo "\n=== Active Alerts ==="
        curl -s "http://localhost:9090/api/v1/alerts" | jq '.data.alerts[] | select(.state=="firing") | {alert: .labels.alertname, instance: .labels.instance, severity: .labels.severity}'
        
        echo "\n=== Disk Usage ==="
        df -h
        
        echo "\n=== Memory Usage ==="
        free -h
        
        echo "\n=== Load Average ==="
        uptime
        
    } > "$health_report"
    
    echo "üìÑ Relat√≥rio de sa√∫de salvo em: $health_report"
    
    # Verificar se h√° problemas cr√≠ticos
    local critical_issues=0
    
    # Verificar servi√ßos
    for service in prometheus grafana-server alertmanager; do
        if ! systemctl is-active --quiet "$service"; then
            echo "‚ùå Servi√ßo $service n√£o est√° ativo"
            ((critical_issues++))
        fi
    done
    
    # Verificar targets down
    local targets_down=$(curl -s "http://localhost:9090/api/v1/targets" | jq '.data.activeTargets[] | select(.health=="down") | .labels.instance' | wc -l)
    
    if [ $targets_down -gt 0 ]; then
        echo "‚ö†Ô∏è $targets_down targets est√£o down"
        ((critical_issues++))
    fi
    
    # Verificar alertas cr√≠ticos
    local critical_alerts=$(curl -s "http://localhost:9090/api/v1/alerts" | jq '.data.alerts[] | select(.state=="firing" and .labels.severity=="critical")' | jq -s length)
    
    if [ $critical_alerts -gt 0 ]; then
        echo "üö® $critical_alerts alertas cr√≠ticos ativos"
        ((critical_issues++))
    fi
    
    if [ $critical_issues -eq 0 ]; then
        echo "‚úÖ Sistema est√° saud√°vel"
        return 0
    else
        echo "‚ùå $critical_issues problemas cr√≠ticos encontrados"
        return 1
    fi
}

# Fun√ß√£o para limpeza autom√°tica
automated_cleanup() {
    echo "üßπ Executando limpeza autom√°tica..."
    
    # Limpar logs antigos
    find "$LOG_DIR" -name "*.log" -mtime +30 -delete
    echo "‚úÖ Logs antigos removidos"
    
    # Limpar m√©tricas antigas do Prometheus (se configurado)
    # Nota: Isso deve ser feito com cuidado em produ√ß√£o
    
    # Limpar backups antigos
    find "$BACKUP_DIR" -name "*.tar.gz" -mtime +30 -delete
    echo "‚úÖ Backups antigos removidos"
    
    # Verificar espa√ßo em disco
    local disk_usage=$(df /opt | tail -1 | awk '{print $5}' | sed 's/%//')
    
    if [ $disk_usage -gt 80 ]; then
        echo "‚ö†Ô∏è Uso de disco alto: ${disk_usage}%"
        # Aqui voc√™ pode adicionar l√≥gica adicional de limpeza
    else
        echo "‚úÖ Uso de disco OK: ${disk_usage}%"
    fi
}

# Fun√ß√£o para atualiza√ß√£o autom√°tica de configura√ß√µes
auto_update_configs() {
    echo "üîÑ Verificando atualiza√ß√µes de configura√ß√£o..."
    
    # Verificar se h√° mudan√ßas no invent√°rio
    if [ "$PROJECT_ROOT/config/inventory.yml" -nt "/etc/prometheus/prometheus.yml" ]; then
        echo "üìù Invent√°rio foi atualizado, regenerando configura√ß√£o do Prometheus..."
        
        # Aqui voc√™ adicionaria a l√≥gica para regenerar a configura√ß√£o
        # baseada no invent√°rio atualizado
        
        # Recarregar configura√ß√£o do Prometheus
        curl -X POST "http://localhost:9090/-/reload"
        
        if [ $? -eq 0 ]; then
            echo "‚úÖ Configura√ß√£o do Prometheus recarregada"
        else
            echo "‚ùå Falha ao recarregar configura√ß√£o do Prometheus"
        fi
    fi
}

# Fun√ß√£o para relat√≥rio de performance
generate_performance_report() {
    echo "üìä Gerando relat√≥rio de performance..."
    
    local report_file="$LOG_DIR/performance_report_$(date +%Y%m%d).html"
    
    cat > "$report_file" << 'EOF'
<!DOCTYPE html>
<html>
<head>
    <title>Infrastructure Performance Report</title>
    <style>
        body { font-family: Arial, sans-serif; margin: 20px; }
        .metric { margin: 10px 0; padding: 10px; border-left: 4px solid #007cba; }
        .critical { border-left-color: #d32f2f; }
        .warning { border-left-color: #f57c00; }
        .ok { border-left-color: #388e3c; }
    </style>
</head>
<body>
    <h1>Infrastructure Performance Report</h1>
    <p>Generated: $(date)</p>
    
    <h2>Server Status</h2>
EOF
    
    # Adicionar m√©tricas de cada servidor
    python3 << 'PYTHON_SCRIPT' >> "$report_file"
import requests
import json
from datetime import datetime

# Consultar Prometheus
prometheus_url = "http://localhost:9090"

# Fun√ß√£o para consultar m√©trica
def query_metric(query):
    try:
        response = requests.get(f"{prometheus_url}/api/v1/query", params={"query": query})
        return response.json()["data"]["result"]
    except:
        return []

# CPU Usage
cpu_data = query_metric("instance:node_cpu_utilization:rate5m")
for item in cpu_data:
    instance = item["metric"]["instance"]
    value = float(item["value"][1])
    status = "critical" if value > 80 else "warning" if value > 60 else "ok"
    print(f'    <div class="metric {status}">')
    print(f'        <strong>{instance}</strong> - CPU: {value:.1f}%')
    print(f'    </div>')

# Memory Usage
mem_data = query_metric("instance:node_memory_utilization:ratio")
for item in mem_data:
    instance = item["metric"]["instance"]
    value = float(item["value"][1])
    status = "critical" if value > 90 else "warning" if value > 75 else "ok"
    print(f'    <div class="metric {status}">')
    print(f'        <strong>{instance}</strong> - Memory: {value:.1f}%')
    print(f'    </div>')

print("</body></html>")
PYTHON_SCRIPT
    
    echo "üìÑ Relat√≥rio de performance salvo em: $report_file"
}

# Fun√ß√£o principal de automa√ß√£o
main_automation() {
    echo "üöÄ Iniciando ciclo de automa√ß√£o..."
    
    # Executar todas as tarefas
    backup_configurations
    
    if automated_health_check; then
        echo "‚úÖ Sistema saud√°vel, continuando automa√ß√£o..."
    else
        echo "‚ö†Ô∏è Problemas detectados, enviando notifica√ß√£o..."
        # Aqui voc√™ pode adicionar notifica√ß√µes (Slack, email, etc.)
    fi
    
    automated_cleanup
    auto_update_configs
    generate_performance_report
    
    echo "üéâ Ciclo de automa√ß√£o conclu√≠do!"
}

# Executar baseado no argumento
case "${1:-main}" in
    "backup")
        backup_configurations
        ;;
    "health")
        automated_health_check
        ;;
    "cleanup")
        automated_cleanup
        ;;
    "update")
        auto_update_configs
        ;;
    "report")
        generate_performance_report
        ;;
    "main")
        main_automation
        ;;
    *)
        echo "Uso: $0 [backup|health|cleanup|update|report|main]"
        exit 1
        ;;
esac
```

## üß™ Exerc√≠cio Final Completo

### Script Principal do Projeto

```bash
#!/bin/bash
# projeto-final-completo.sh

echo "üéØ PROJETO FINAL: Monitoramento Completo de Infraestrutura"
echo "=========================================================="

# Verificar pr√©-requisitos
check_prerequisites() {
    echo "üîç Verificando pr√©-requisitos..."
    
    local missing_tools=()
    
    for tool in curl jq python3 ssh systemctl; do
        if ! command -v "$tool" &> /dev/null; then
            missing_tools+=("$tool")
        fi
    done
    
    if [ ${#missing_tools[@]} -gt 0 ]; then
        echo "‚ùå Ferramentas faltando: ${missing_tools[*]}"
        echo "Instale as ferramentas necess√°rias antes de continuar."
        exit 1
    fi
    
    echo "‚úÖ Todos os pr√©-requisitos atendidos"
}

# Fase 1: Setup da estrutura
phase1_setup() {
    echo "\nüìã FASE 1: Setup da Estrutura do Projeto"
    echo "========================================"
    
    ./setup-project-structure.sh
    
    if [ $? -eq 0 ]; then
        echo "‚úÖ Fase 1 conclu√≠da com sucesso"
        return 0
    else
        echo "‚ùå Falha na Fase 1"
        return 1
    fi
}

# Fase 2: Deploy do Node Exporter
phase2_deploy() {
    echo "\nüöÄ FASE 2: Deploy do Node Exporter"
    echo "=================================="
    
    # Simular deploy (em ambiente real, descomente a linha abaixo)
    # ./deploy-node-exporter-fleet.sh
    
    echo "üì¶ Simulando deploy do Node Exporter em todos os servidores..."
    sleep 3
    
    # Verificar se os exporters est√£o respondendo (simulado)
    echo "üîç Verificando status dos Node Exporters..."
    
    local servers=("web-01:192.168.1.10" "web-02:192.168.1.11" "db-01:192.168.1.20" "lb-01:192.168.1.5")
    
    for server in "${servers[@]}"; do
        local name=$(echo "$server" | cut -d: -f1)
        local ip=$(echo "$server" | cut -d: -f2)
        
        echo "  üìä $name ($ip): Node Exporter ativo ‚úÖ"
    done
    
    echo "‚úÖ Fase 2 conclu√≠da com sucesso"
}

# Fase 3: Configura√ß√£o do Prometheus
phase3_prometheus() {
    echo "\n‚öôÔ∏è FASE 3: Configura√ß√£o do Prometheus"
    echo "===================================="
    
    # Copiar configura√ß√£o do Prometheus
    local config_dir="/opt/infrastructure-monitoring/config/prometheus"
    
    echo "üìù Criando configura√ß√£o do Prometheus..."
    
    # A configura√ß√£o j√° foi criada anteriormente no arquivo prometheus-infrastructure.yml
    echo "‚úÖ Configura√ß√£o do Prometheus criada"
    
    # Simular reload do Prometheus
    echo "üîÑ Recarregando configura√ß√£o do Prometheus..."
    # curl -X POST "http://localhost:9090/-/reload"
    
    echo "‚úÖ Fase 3 conclu√≠da com sucesso"
}

# Fase 4: Setup de Alertas
phase4_alerts() {
    echo "\nüö® FASE 4: Configura√ß√£o de Alertas"
    echo "=================================="
    
    local alerts_dir="/opt/infrastructure-monitoring/alerts"
    
    echo "üìã Configurando regras de alerta..."
    
    # As regras j√° foram criadas anteriormente no arquivo infrastructure-alerts.yml
    echo "‚úÖ Regras de alerta configuradas"
    
    echo "üìß Configurando Alertmanager..."
    
    cat > "$alerts_dir/alertmanager.yml" << 'EOF'
global:
  smtp_smarthost: 'localhost:587'
  smtp_from: 'alerts@company.com'

route:
  group_by: ['alertname', 'severity']
  group_wait: 10s
  group_interval: 10s
  repeat_interval: 1h
  receiver: 'web.hook'
  routes:
  - match:
      severity: critical
    receiver: 'critical-alerts'
  - match:
      severity: warning
    receiver: 'warning-alerts'

receivers:
- name: 'web.hook'
  webhook_configs:
  - url: 'http://localhost:5001/'

- name: 'critical-alerts'
  email_configs:
  - to: 'oncall@company.com'
    subject: 'CRITICAL: {{ .GroupLabels.alertname }}'
    body: |
      {{ range .Alerts }}
      Alert: {{ .Annotations.summary }}
      Description: {{ .Annotations.description }}
      {{ end }}
  slack_configs:
  - api_url: 'https://hooks.slack.com/services/YOUR/SLACK/WEBHOOK'
    channel: '#alerts-critical'
    title: 'Critical Alert'
    text: '{{ range .Alerts }}{{ .Annotations.summary }}{{ end }}'

- name: 'warning-alerts'
  email_configs:
  - to: 'team@company.com'
    subject: 'WARNING: {{ .GroupLabels.alertname }}'
  slack_configs:
  - api_url: 'https://hooks.slack.com/services/YOUR/SLACK/WEBHOOK'
    channel: '#alerts-warning'
    title: 'Warning Alert'
    text: '{{ range .Alerts }}{{ .Annotations.summary }}{{ end }}'
EOF
    
    echo "‚úÖ Fase 4 conclu√≠da com sucesso"
}

# Fase 5: Cria√ß√£o de Dashboards
phase5_dashboards() {
    echo "\nüìä FASE 5: Cria√ß√£o de Dashboards"
    echo "================================"
    
    ./create-infrastructure-dashboards.sh
    
    if [ $? -eq 0 ]; then
        echo "‚úÖ Fase 5 conclu√≠da com sucesso"
    else
        echo "‚ö†Ô∏è Alguns dashboards podem n√£o ter sido criados corretamente"
    fi
}

# Fase 6: Automa√ß√£o
phase6_automation() {
    echo "\nü§ñ FASE 6: Configura√ß√£o de Automa√ß√£o"
    echo "===================================="
    
    echo "‚è∞ Configurando tarefas automatizadas..."
    
    # Adicionar ao cron
    cat > "/tmp/monitoring_cron" << 'EOF'
# Backup di√°rio √†s 2:00
0 2 * * * /opt/infrastructure-monitoring/scripts/infrastructure-automation.sh backup

# Health check a cada 15 minutos
*/15 * * * * /opt/infrastructure-monitoring/scripts/infrastructure-automation.sh health

# Limpeza semanal aos domingos √†s 3:00
0 3 * * 0 /opt/infrastructure-monitoring/scripts/infrastructure-automation.sh cleanup

# Relat√≥rio de performance di√°rio √†s 8:00
0 8 * * * /opt/infrastructure-monitoring/scripts/infrastructure-automation.sh report
EOF
    
    # crontab /tmp/monitoring_cron
    echo "‚úÖ Tarefas automatizadas configuradas"
    
    echo "‚úÖ Fase 6 conclu√≠da com sucesso"
}

# Fase 7: Valida√ß√£o Final
phase7_validation() {
    echo "\n‚úÖ FASE 7: Valida√ß√£o Final do Projeto"
    echo "====================================="
    
    local validation_score=0
    local total_checks=10
    
    echo "üîç Executando valida√ß√£o completa..."
    
    # Check 1: Estrutura do projeto
    if [ -d "/opt/infrastructure-monitoring" ]; then
        echo "‚úÖ Estrutura do projeto criada"
        ((validation_score++))
    else
        echo "‚ùå Estrutura do projeto n√£o encontrada"
    fi
    
    # Check 2: Configura√ß√£o do Prometheus
    if [ -f "/opt/infrastructure-monitoring/config/prometheus/prometheus-infrastructure.yml" ]; then
        echo "‚úÖ Configura√ß√£o do Prometheus criada"
        ((validation_score++))
    else
        echo "‚ùå Configura√ß√£o do Prometheus n√£o encontrada"
    fi
    
    # Check 3: Regras de alerta
    if [ -f "/opt/infrastructure-monitoring/alerts/infrastructure-alerts.yml" ]; then
        echo "‚úÖ Regras de alerta configuradas"
        ((validation_score++))
    else
        echo "‚ùå Regras de alerta n√£o encontradas"
    fi
    
    # Check 4: Dashboards
    if [ -f "/opt/infrastructure-monitoring/dashboards/infrastructure-overview.json" ]; then
        echo "‚úÖ Dashboards criados"
        ((validation_score++))
    else
        echo "‚ùå Dashboards n√£o encontrados"
    fi
    
    # Check 5: Scripts de automa√ß√£o
    if [ -f "/opt/infrastructure-monitoring/scripts/infrastructure-automation.sh" ]; then
        echo "‚úÖ Scripts de automa√ß√£o criados"
        ((validation_score++))
    else
        echo "‚ùå Scripts de automa√ß√£o n√£o encontrados"
    fi
    
    # Check 6: Invent√°rio de servidores
    if [ -f "/opt/infrastructure-monitoring/config/inventory.yml" ]; then
        echo "‚úÖ Invent√°rio de servidores configurado"
        ((validation_score++))
    else
        echo "‚ùå Invent√°rio de servidores n√£o encontrado"
    fi
    
    # Check 7: Scripts de deploy
    if [ -f "/opt/infrastructure-monitoring/scripts/deploy-node-exporter-fleet.sh" ]; then
        echo "‚úÖ Scripts de deploy criados"
        ((validation_score++))
    else
        echo "‚ùå Scripts de deploy n√£o encontrados"
    fi
    
    # Check 8: Configura√ß√£o do Alertmanager
    if [ -f "/opt/infrastructure-monitoring/alerts/alertmanager.yml" ]; then
        echo "‚úÖ Configura√ß√£o do Alertmanager criada"
        ((validation_score++))
    else
        echo "‚ùå Configura√ß√£o do Alertmanager n√£o encontrada"
    fi
    
    # Check 9: Documenta√ß√£o
    if [ -d "/opt/infrastructure-monitoring/docs" ]; then
        echo "‚úÖ Estrutura de documenta√ß√£o criada"
        ((validation_score++))
    else
        echo "‚ùå Estrutura de documenta√ß√£o n√£o encontrada"
    fi
    
    # Check 10: Logs e backup
    if [ -d "/opt/infrastructure-monitoring/logs" ] && [ -d "/opt/infrastructure-monitoring/backup" ]; then
        echo "‚úÖ Diret√≥rios de logs e backup criados"
        ((validation_score++))
    else
        echo "‚ùå Diret√≥rios de logs e backup n√£o encontrados"
    fi
    
    echo "\nüìä Pontua√ß√£o Final: $validation_score/$total_checks"
    
    if [ $validation_score -eq $total_checks ]; then
        echo "üèÜ EXCELENTE! Projeto implementado com sucesso!"
        return 0
    elif [ $validation_score -ge 8 ]; then
        echo "üéâ MUITO BOM! Projeto quase completo!"
        return 0
    elif [ $validation_score -ge 6 ]; then
        echo "üëç BOM! Projeto funcional com algumas melhorias necess√°rias!"
        return 1
    else
        echo "üìö PRECISA MELHORAR! Revise a implementa√ß√£o!"
        return 1
    fi
}

# Fun√ß√£o principal
main() {
    echo "üöÄ Iniciando Projeto Final de Monitoramento de Infraestrutura"
    echo "============================================================="
    
    check_prerequisites
    
    # Executar todas as fases
    phase1_setup && \
    phase2_deploy && \
    phase3_prometheus && \
    phase4_alerts && \
    phase5_dashboards && \
    phase6_automation && \
    phase7_validation
    
    local exit_code=$?
    
    if [ $exit_code -eq 0 ]; then
        echo "\nüéâ PROJETO FINAL CONCLU√çDO COM SUCESSO!"
        echo "======================================="
        echo "\nüìã Resumo do que foi implementado:"
        echo "  ‚úÖ Estrutura completa do projeto"
        echo "  ‚úÖ Deploy automatizado do Node Exporter"
        echo "  ‚úÖ Configura√ß√£o avan√ßada do Prometheus"
        echo "  ‚úÖ Sistema de alertas robusto"
        echo "  ‚úÖ Dashboards personalizados"
        echo "  ‚úÖ Automa√ß√£o e orquestra√ß√£o"
        echo "\nüîó Pr√≥ximos passos:"
        echo "  1. Revisar e personalizar as configura√ß√µes"
        echo "  2. Testar em ambiente de desenvolvimento"
        echo "  3. Implementar em produ√ß√£o gradualmente"
        echo "  4. Treinar a equipe nos procedimentos"
        echo "  5. Documentar runbooks espec√≠ficos"
    else
        echo "\n‚ö†Ô∏è PROJETO PARCIALMENTE IMPLEMENTADO"
        echo "===================================="
        echo "\nRevise os itens que falharam e tente novamente."
    fi
}

# Executar projeto
main
```

## üìö Crit√©rios de Avalia√ß√£o

### Checklist de Valida√ß√£o

```bash
#!/bin/bash
# validacao-projeto-final.sh

echo "üìã Valida√ß√£o do Projeto Final"
echo "============================"

SCORE=0
TOTAL=20

# Categoria 1: Estrutura e Organiza√ß√£o (5 pontos)
echo "\nüìÅ 1. ESTRUTURA E ORGANIZA√á√ÉO"
echo "============================="

if [ -d "/opt/infrastructure-monitoring" ]; then
    echo "‚úÖ Diret√≥rio principal criado"
    ((SCORE++))
else
    echo "‚ùå Diret√≥rio principal n√£o encontrado"
fi

if [ -f "/opt/infrastructure-monitoring/config/inventory.yml" ]; then
    echo "‚úÖ Invent√°rio de servidores configurado"
    ((SCORE++))
else
    echo "‚ùå Invent√°rio de servidores n√£o configurado"
fi

if [ -d "/opt/infrastructure-monitoring/scripts" ]; then
    echo "‚úÖ Diret√≥rio de scripts criado"
    ((SCORE++))
else
    echo "‚ùå Diret√≥rio de scripts n√£o encontrado"
fi

if [ -d "/opt/infrastructure-monitoring/dashboards" ]; then
    echo "‚úÖ Diret√≥rio de dashboards criado"
    ((SCORE++))
else
    echo "‚ùå Diret√≥rio de dashboards n√£o encontrado"
fi

if [ -d "/opt/infrastructure-monitoring/docs" ]; then
    echo "‚úÖ Documenta√ß√£o estruturada"
    ((SCORE++))
else
    echo "‚ùå Documenta√ß√£o n√£o estruturada"
fi

# Categoria 2: Configura√ß√£o do Prometheus (4 pontos)
echo "\n‚öôÔ∏è 2. CONFIGURA√á√ÉO DO PROMETHEUS"
echo "==============================="

if [ -f "/opt/infrastructure-monitoring/config/prometheus/prometheus-infrastructure.yml" ]; then
    echo "‚úÖ Configura√ß√£o do Prometheus criada"
    ((SCORE++))
    
    if grep -q "node-exporter-web" "/opt/infrastructure-monitoring/config/prometheus/prometheus-infrastructure.yml"; then
        echo "‚úÖ Jobs de Node Exporter configurados"
        ((SCORE++))
    else
        echo "‚ùå Jobs de Node Exporter n√£o configurados"
    fi
    
    if grep -q "relabel_configs" "/opt/infrastructure-monitoring/config/prometheus/prometheus-infrastructure.yml"; then
        echo "‚úÖ Relabeling configurado"
        ((SCORE++))
    else
        echo "‚ùå Relabeling n√£o configurado"
    fi
    
    if grep -q "recording_rules" "/opt/infrastructure-monitoring/config/prometheus/prometheus-infrastructure.yml"; then
        echo "‚úÖ Recording rules configuradas"
        ((SCORE++))
    else
        echo "‚ùå Recording rules n√£o configuradas"
    fi
else
    echo "‚ùå Configura√ß√£o do Prometheus n√£o encontrada"
fi

# Categoria 3: Sistema de Alertas (4 pontos)
echo "\nüö® 3. SISTEMA DE ALERTAS"
echo "======================="

if [ -f "/opt/infrastructure-monitoring/alerts/infrastructure-alerts.yml" ]; then
    echo "‚úÖ Regras de alerta criadas"
    ((SCORE++))
    
    if grep -q "HighCPUUsage" "/opt/infrastructure-monitoring/alerts/infrastructure-alerts.yml"; then
        echo "‚úÖ Alertas de CPU configurados"
        ((SCORE++))
    else
        echo "‚ùå Alertas de CPU n√£o configurados"
    fi
    
    if grep -q "HighMemoryUsage" "/opt/infrastructure-monitoring/alerts/infrastructure-alerts.yml"; then
        echo "‚úÖ Alertas de mem√≥ria configurados"
        ((SCORE++))
    else
        echo "‚ùå Alertas de mem√≥ria n√£o configurados"
    fi
    
    if grep -q "ServerDown" "/opt/infrastructure-monitoring/alerts/infrastructure-alerts.yml"; then
        echo "‚úÖ Alertas de disponibilidade configurados"
        ((SCORE++))
    else
        echo "‚ùå Alertas de disponibilidade n√£o configurados"
    fi
else
    echo "‚ùå Regras de alerta n√£o encontradas"
fi

# Categoria 4: Dashboards e Visualiza√ß√£o (3 pontos)
echo "\nüìä 4. DASHBOARDS E VISUALIZA√á√ÉO"
echo "==============================="

if [ -f "/opt/infrastructure-monitoring/dashboards/infrastructure-overview.json" ]; then
    echo "‚úÖ Dashboard de infraestrutura criado"
    ((SCORE++))
else
    echo "‚ùå Dashboard de infraestrutura n√£o encontrado"
fi

if [ -f "/opt/infrastructure-monitoring/dashboards/application-metrics.json" ]; then
    echo "‚úÖ Dashboard de aplica√ß√µes criado"
    ((SCORE++))
else
    echo "‚ùå Dashboard de aplica√ß√µes n√£o encontrado"
fi

if [ -f "/opt/infrastructure-monitoring/dashboards/security-monitoring.json" ]; then
    echo "‚úÖ Dashboard de seguran√ßa criado"
    ((SCORE++))
else
    echo "‚ùå Dashboard de seguran√ßa n√£o encontrado"
fi

# Categoria 5: Automa√ß√£o e Scripts (4 pontos)
echo "\nü§ñ 5. AUTOMA√á√ÉO E SCRIPTS"
echo "========================="

if [ -f "/opt/infrastructure-monitoring/scripts/deploy-node-exporter-fleet.sh" ]; then
    echo "‚úÖ Script de deploy criado"
    ((SCORE++))
else
    echo "‚ùå Script de deploy n√£o encontrado"
fi

if [ -f "/opt/infrastructure-monitoring/scripts/infrastructure-automation.sh" ]; then
    echo "‚úÖ Script de automa√ß√£o criado"
    ((SCORE++))
else
    echo "‚ùå Script de automa√ß√£o n√£o encontrado"
fi

if [ -f "/opt/infrastructure-monitoring/scripts/health-check.sh" ]; then
    echo "‚úÖ Script de health check criado"
    ((SCORE++))
else
    echo "‚ùå Script de health check n√£o encontrado"
fi

if [ -f "/opt/infrastructure-monitoring/scripts/backup-configs.sh" ]; then
    echo "‚úÖ Script de backup criado"
    ((SCORE++))
else
    echo "‚ùå Script de backup n√£o encontrado"
fi

# Resultado final
echo "\nüìà RESULTADO FINAL"
echo "=================="
echo "Pontua√ß√£o: $SCORE/$TOTAL"

if [ $SCORE -eq $TOTAL ]; then
    echo "üèÜ EXCELENTE! (100%) - Projeto perfeito!"
    exit 0
elif [ $SCORE -ge 18 ]; then
    echo "ü•á MUITO BOM! (90%+) - Projeto quase perfeito!"
    exit 0
elif [ $SCORE -ge 16 ]; then
    echo "ü•à BOM! (80%+) - Projeto bem implementado!"
    exit 0
elif [ $SCORE -ge 14 ]; then
    echo "ü•â SATISFAT√ìRIO! (70%+) - Projeto funcional!"
    exit 0
elif [ $SCORE -ge 10 ]; then
    echo "üìö PRECISA MELHORAR! (50%+) - Revise alguns pontos!"
    exit 1
else
    echo "‚ùå INSUFICIENTE! (<50%) - Refa√ßa o projeto!"
    exit 1
fi
```

## üéØ Objetivos de Aprendizagem

### Ao completar este projeto final, voc√™ ser√° capaz de:

1. **Arquitetar** uma solu√ß√£o completa de monitoramento
2. **Implementar** Node Exporter em m√∫ltiplos servidores
3. **Configurar** Prometheus com service discovery avan√ßado
4. **Criar** dashboards personalizados no Grafana
5. **Definir** alertas inteligentes e eficazes
6. **Automatizar** tarefas de manuten√ß√£o e opera√ß√£o
7. **Documentar** procedimentos e runbooks
8. **Troubleshooting** de problemas complexos
9. **Otimizar** performance do sistema de monitoramento
10. **Integrar** com ferramentas de notifica√ß√£o

## üìñ Documenta√ß√£o Adicional

### Runbooks Recomendados

1. **Procedimento de Emerg√™ncia**
   - Escala√ß√£o de alertas cr√≠ticos
   - Contatos de emerg√™ncia
   - Procedimentos de rollback

2. **Manuten√ß√£o Preventiva**
   - Limpeza de m√©tricas antigas
   - Atualiza√ß√£o de componentes
   - Backup de configura√ß√µes

3. **Troubleshooting Comum**
   - Node Exporter n√£o responde
   - M√©tricas ausentes
   - Alertas falso-positivos

4. **Procedimentos de Expans√£o**
   - Adi√ß√£o de novos servidores
   - Cria√ß√£o de novos dashboards
   - Configura√ß√£o de novos alertas

## üîó Recursos Adicionais

- [Documenta√ß√£o Oficial do Node Exporter](https://github.com/prometheus/node_exporter)
- [Prometheus Best Practices](https://prometheus.io/docs/practices/)
- [Grafana Dashboard Gallery](https://grafana.com/grafana/dashboards/)
- [Alertmanager Configuration](https://prometheus.io/docs/alerting/latest/configuration/)

## üìù Resumo do M√≥dulo

Neste m√≥dulo final, voc√™ implementou um **projeto completo de monitoramento de infraestrutura** que integra todos os conceitos aprendidos nos m√≥dulos anteriores:

### ‚úÖ **Principais Conquistas:**

1. **Arquitetura Robusta**: Estrutura modular e escal√°vel
2. **Deploy Automatizado**: Scripts para implanta√ß√£o em m√∫ltiplos servidores
3. **Monitoramento Abrangente**: M√©tricas de sistema, aplica√ß√£o e seguran√ßa
4. **Alertas Inteligentes**: Regras cr√≠ticas e preditivas
5. **Visualiza√ß√£o Avan√ßada**: Dashboards personalizados e informativos
6. **Automa√ß√£o Completa**: Tarefas de manuten√ß√£o e opera√ß√£o
7. **Documenta√ß√£o Estruturada**: Procedimentos e runbooks

### üéì **Compet√™ncias Desenvolvidas:**

- Planejamento e arquitetura de solu√ß√µes de monitoramento
- Implementa√ß√£o e configura√ß√£o de Node Exporter em escala
- Integra√ß√£o avan√ßada com Prometheus e Grafana
- Cria√ß√£o de alertas eficazes e n√£o intrusivos
- Automa√ß√£o de tarefas operacionais
- Troubleshooting e otimiza√ß√£o de performance
- Documenta√ß√£o t√©cnica e procedimentos operacionais

---

## üß≠ Navega√ß√£o

- [‚Üê M√≥dulo 06: Troubleshooting e Otimiza√ß√£o](06-troubleshooting-otimizacao.md)
- [üè† P√°gina Principal](../README.md)
- [üìö Documenta√ß√£o cAdvisor](../cadvisor/README.md)

---

**üéâ Parab√©ns!** Voc√™ concluiu com sucesso a especializa√ß√£o em **Node Exporter**! 

Agora voc√™ possui as habilidades necess√°rias para implementar, configurar e manter um sistema robusto de monitoramento de infraestrutura em ambientes de produ√ß√£o.

**Pr√≥ximos passos sugeridos:**
1. Implementar o projeto em um ambiente de teste
2. Personalizar as configura√ß√µes para seu contexto espec√≠fico
3. Treinar sua equipe nos procedimentos desenvolvidos
4. Expandir o monitoramento para outras tecnologias
5. Contribuir com a comunidade compartilhando suas experi√™ncias